# -*- mode:org; -*-

#+title:Developing GitHub Apps
#+subtitle:{{{version}}} {{{date}}}
#+author:WLH4
#+date:2020-12-17 09:26
#+macro:version Version 0.0.3
#+macro:upload-date (eval (current-time-string))
#+bucket:pinecone-forest.com

{{{version}}} {{{date}}}

#+texinfo:@insertcopying


* Introduction
:PROPERTIES:
:unnumbered: t
:url:      https://docs.github.com/en/free-pro-team@latest/developers
:END:
* GitHub Main
- [[https://docs.github.com/en/free-pro-team@latest/github][GitHub]]
** Getting Started
** GitHub Account
** GitHub Profile
** Authenticating to GitHub
Keep your account and data secure with features like two-factor authentication,
SSH, and commit signature verification.

- [[https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github][Authenticating]]
*** Keeping Account and Data Secure
To protect your personal information, you  should keep both your GitHub account
and any associated data secure.
**** About Authentication
You can securely  access your account's resources by  authenticating to GitHub,
using different credentials depending on where you authenticate.
***** About Authentication
To  keep your  account  secure, you  must authenticate  before  you can  access
certain resources on GitHub.

When you  authenticate to GitHub,  you supply  or confirm credentials  that are
unique to you to prove that you are exactly who you declare to be.

You can  access your  resources in  GitHub in a  variety of  ways. Each  way of
accessing GitHub supports different modes of authentication.
- in the browser
- via GitHub Desktop
- with the API
- via the command line
***** Authenticating in your Browser
You can authenticate to GitHub in your browser in different ways.

****** Username and password only
- You'll create a password when you create your user account on GitHub
- For more information, see [[https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/creating-a-strong-password]["Creating a strong password."]]

****** Two-factor authentication (2FA)
- If you enable 2FA,  we'll also prompt you to provide  a code that's generated
  by an application on your mobile device or sent as a text message (SMS) after
  you successfully enter your username and password.
- For more information, see [[Accessing GitHub using two-factor authentication]["Accessing GitHub using two-factor authentication."]]
- In addition  to authentication with a  mobile application or a  text message,
  you can optionally  add a secondary method of authentication  with a security
  key using ~WebAuthn~.
- For  more information,  see  [[https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-a-security-key]["Configuring two-factor  authentication using  a
  security key."]]

***** Authenticating with GitHub Desktop
You can authenticate with GitHub Desktop using your browser.
- For more information, see [[https://docs.github.com/en/free-pro-team@latest/desktop/getting-started-with-github-desktop/authenticating-to-github]["Authenticating to GitHub."]]

***** Authenticating with the API
You can authenticate with the API in different ways.

****** Personal access tokens
- In limited situations,  such as testing, you can use  a personal access token
  to access the API.
- Using a personal access token enables you to revoke access at any time.
- For more information, see [[https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/creating-a-personal-access-token]["Creating a personal access token."]]

****** Web application flow
- For OAuth Apps in production, you should authenticate using the web
  application flow.
- For more information, see [[https://docs.github.com/en/free-pro-team@latest/apps/building-oauth-apps/authorizing-oauth-apps/#web-application-flow]["Authorizing OAuth Apps."]]

****** GitHub Apps
- For GitHub Apps  in production, you should authenticate on  behalf of the app
  installation.
- For more information, see [[https://docs.github.com/en/free-pro-team@latest/apps/building-github-apps/authenticating-with-github-apps]["Authenticating with GitHub Apps."]]

***** Authenticating with the Command Line
You can access  repositories on GitHub from  the command line in  two ways. The
method of authenticating is determined based  on whether you choose an HTTPS or
SSH remote URL when you clone the repository.
- HTTPS
- SSH

For more information about which way to  access, see [[https://docs.github.com/en/free-pro-team@latest/github/using-git/which-remote-url-should-i-use]["Which remote URL should I
use?"]]

****** Authenticating over HTTPS
- You can  work with  all repositories on  GitHub over HTTPS,  even if  you are
  behind a firewall or proxy.

- Every time  you use Git  to authenticate with  GitHub, you'll be  prompted to
  enter your credentials to authenticate with GitHub

  - unless you cache them with a [[https://docs.github.com/en/free-pro-team@latest/github/using-git/caching-your-github-credentials-in-git][credential helper]].

- When Git  prompts you  for your  password, enter  your personal  access token
  (PAT) instead. Password-based authentication for Git is deprecated, and using
  a PAT is more secure.

****** Authenticating using SSH
- You can work with all repositories on GitHub over SSH, although firewalls and
  proxys might refuse to allow SSH connections.

- Using SSH  requires you  to generate  an SSH  public/private keypair  on your
  local machine and add the public key to your GitHub account.

- Every time  you use Git  to authenticate with  GitHub, you'll be  prompted to
  enter your SSH key passphrase

  - unless you've [[https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent#adding-your-ssh-key-to-the-ssh-agent][stored the key]].

- For more information, see [[https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent]["Generating a new SSH key and adding it to the
  ssh-agent."]]

**** Strong Password
**** GitHub Access Credentials
**** Personal Access Token
You should create  a personal access token  to use in place of  a password with
the  command  line or  with  the  API. Personal  access  tokens  (PATs) are  an
alternative  to using  passwords for  authentication to  GitHub when  using the
GitHub API or the command line.

***** Create a Token
- Settings
- Developer Settings
- Personal Access Tokens
- Generate New Token
- Description
- Select Scopes or Permissions
- Generate Token
- Copy Token to the Clipboard

***** Use the Token on the Command Line
Once  you  have a  token,  you  can enter  it  instead  of your  password  when
performing Git operations over HTTPS.

#+begin_example
  $ git clone https://github.com/username/repo.git
  Username: your_username
  Password: your_token
#+end_example

Personal  access tokens  can only  be used  for HTTPS  Git operations.  If your
repository uses an SSH remote URL, you  will need to switch the remote from SSH
to HTTPS.

If you are not prompted for your username and password, your credentials may be
cached on  your computer. You  can [[https://docs.github.com/en/free-pro-team@latest/articles/updating-credentials-from-the-osx-keychain][update your  credentials in the  Keychain]] to
replace your old password with the token.

**** SSH Keys
**** Deploye Keys
**** Authorizing OAuth Apps
**** Authorized Integrations
**** Third-Party Applications
**** Authorized Applications
**** Security Log
**** Remove Sensitive Data from a Repository
**** Anonymized Image URLs
**** GitHub's IP Addresses
**** GitHub's SSH Fingerprints
**** Sudo Mode
**** Preventing Unauthorized Access

*** Two-Factor Authentication
*** Connecting to GitHub with SSH
*** Commit Signature Verification
** Using Git
- [[https://docs.github.com/en/free-pro-team@latest/github/using-git][Using Git]]
*** Getting Started with Git
**** Username in Git
#+cindex:username, Git
#+cindex:Git username
#+cindex:GitHub username
Git uses a username to associate commits  with an identity. The Git username is
not the same as your GitHub username.

You can change the name that is associated with your Git commits using the ~git
config~ command. The new name you set will be visible in any future commits you
push to  GitHub from the  command line.  If you'd like  to keep your  real name
private, you can use any text as your Git username.

***** Setting your Git username for every repository on your computer
: $ git config --global user.name "Mona Lisa"
: $ git config --global user.email "email@example.com"

To confirm:
: $ git config --global user.name
: > Mona Lisa

: $ git config --global user.email
: email@example.com

***** Setting your Git username for a single repository
: $ git config user.name "Mona Lisa"
: $ git config user.email "email@example.com"

To confirm:
: $ git config user.name
: > Mona Lisa

: $ git config user.email
: email@example.com

**** Git and Passwords
If Git prompts you  for a username and password every time  you try to interact
with GitHub, you're probably using the HTTPS clone URL for your repository.

Using an HTTPS remote URL has some advantages compared with using SSH.
- It's easier to set up than SSH
- usually works through strict firewalls and proxies
- However, it also prompts you to  enter your GitHub credentials every time you
  pull or push a repository.

When Git prompts you for your  password, enter your personal access token (PAT)
instead.

You can avoid being prompted for your password by configuring Git to cache your
credentials   for  you.   Once  you've   configured  credential   caching,  Git
automatically uses  your cached personal access  token when you pull  or push a
repository using HTTPS.

**** Caching Git Credentials in Git
#+cindex:credential-helper
#+cindex:cache credentials
#+cindex:credential-osxkeychain
If you're  cloning GitHub repositories  using HTTPS,  you can use  a credential
helper to tell Git to remember your credentials.

1. Find out if Git and the osxkeychain helper are already installed:

   #+begin_example
     $ git credential-osxkeychain
     # Test for the cred helper
     > Usage: git credential-osxkeychain <get|store|erase>
   #+end_example

2.  Tell Git  to use  osxkeychain helper  using the  global =credential.helper=
   config:

   #+begin_example
     $ git config --global credential.helper osxkeychain
     # Set git to use the osxkeychain credential helper
   #+end_example

3. Add Your Credentials

   The next time you clone an  HTTPS URL that requires authentication, Git will
   prompt you  for your username  and password. When  Git prompts you  for your
   password, enter your personal access token (PAT) instead.

   Once you've authenticated  successfully, your credentials are  stored in the
   macOS keychain and will be used every time you clone an HTTPS URL. You won't
   be required to type your credentials in  to Git again unless you change your
   credentials.

**** Updating or Deleting Credentials from the macOS Keychain
#+cindex:git-credential-oskeychain helper
You'll     need    to     update    your     saved    credentials     in    the
~git-credential-osxkeychain~ helper if you change your:
- username,
- password,  or
- personal  access token

on GitHub.

***** Updating your credentials via Keychain Access
#+cindex:keychain access
1. Click on the Spotlight icon (magnifying glass) on the right side of the menu
   bar. Type Keychain access then press the Enter key to launch the app.

2. In Keychain Access, search for ~github.com~.

3. Find the "internet password" entry for github.com.

4. Edit or delete the entry accordingly.

***** Deleting your credentials via the command line
#+cindex:erase keychain credential
Through the command  line, you can use the credential  helper directly to erase
the keychain entry.

#+begin_example
$ git credential-osxkeychain erase
host=github.com
protocol=https
> [Press Return]
#+end_example

If it's  successful, nothing  will print out.  To test that  it works,  try and
clone  a repository  from  GitHub. If  you  are prompted  for  a password,  the
keychain entry was deleted.
*** Learning About Git
*** Common Git Commands
*** Managing Remote Repositories
*** Advanced Git Commands
* Developers
Go deeper with GitHub.

- integrate with GitHub's APIs
- customize GitHub workflow
- build and share apps

** Overview
- Learn about GitHub's APIs
- Secure deployments
- Join GitHub's Developer Program

*** About GitHub's APIs

#+cindex:API, GitHub,REST,GraphQL
#+cindex:REST API
#+cindex:GraphQL API
Two stable versions of GitHub's API:

1. the REST API, currently v3

   #+cindex:Accept header
   #+cindex:header, Accept
   - request v3 via the =Accept= header ::

     - All GitHub media types look like this:
       : application/vnd.github[.version].param[+json]

       : -H "Accept: application/vnd.github.v3+json"
       : -H "Accept: application/vnd.github.v3.full+json"

     - The most basic media types the API supports are:
       : application/json
       : application/vnd.github+json

       Neither of these  specify a version, so you will  always get the current
       default JSON representation of resources.

     - You can specify a version like so:
       : application/vnd.github.v3+json

     - If you're specifying a property (such as text/full/raw/html/etc defined below),
       put the version before the property:
       : application/vnd.github.v3.raw+json

     - You can check the current version through every response's headers. Look
       for the X-GitHub-Media-Type header:
       : -H "Accept: application/vnd.github.full+json"
       : ==> X-GitHub-Media-Type: github.v3
       : -H "Accept: application/vnd.github.v3.full+json"
       : ==> X-GitHub-Media-Type: github.v3; param=full; format=json

2. [[https://docs.github.com/en/free-pro-team@latest/graphql][the GraphQL API]]

*** Managing Deploy Keys

#+cindex:deploy keys
#+cindex:keys, deploy, SSH
#+cindex:SSH keys
#+cindex:deployment scripts
Learn  different ways  to manage  SSH keys  on your  servers when  you automate
deployment scripts.

You can  manage SSH  keys on  your servers  when automating  deployment scripts
using:

- SSH Agent Forwarding
- HTTPS with OAuth tokens
- deploy keys
- machine users

**** SSH Agent Forwarding

#+cindex:SSH Agent Forwarding
Agent forwarding  uses the same SSH  keys that your local  development computer
uses.

- In many cases, especially in the beginning of a project, SSH agent forwarding
  is the quickest and simplest method to use.

***** Pros
- You do not have to generate or keep track of any new keys.
- There is  no key management;  users have the  same permissions on  the server
  that they do locally.
- No keys are stored  on the server, so in case the  server is compromised, you
  don't need to hunt down and remove the compromised keys.

***** Cons
- Users must SSH in to deploy; automated deploy processes can't be used.
- SSH agent forwarding can be troublesome to run for Windows users.

***** Setup
1. [[https://docs.github.com/en/free-pro-team@latest/guides/using-ssh-agent-forwarding][Turn on agent forwarding locally.]]

2. Set  your deploy  scripts to use  agent forwarding. For  example, on  a bash
   script, enabling agent forwarding would look something like this:

   : ssh -A serverA 'bash -s' < deploy.sh

**** HTTPS cloning with OAuth tokens

#+cindex:OAuth Token
If you don't want to use SSH keys, you can use HTTPS with OAuth tokens.

***** Pros
- Anyone with access to the server can deploy the repository.
- Users don't have to change their local SSH settings.
- Multiple tokens (one for  each user) are not needed; one  token per server is
  enough.
- A token can be revoked at any time, turning it essentially into a one-use
  password.
- Generating new tokens can be easily scripted using the OAuth API.

***** Cons
- You must  make sure  that you  configure your token  with the  correct access
  scopes.
- Tokens are essentially passwords, and must be protected the same way.

***** Setup
[[https://docs.github.com/en/free-pro-team@latest/articles/git-automation-with-oauth-tokens][Guide on Git automation with tokens]]

**** Deploy Keys

#+cindex:Deploy key
You can  launch projects  from a GitHub  repository to your  server by  using a
deploy key, which is an SSH key that grants access to a single repository.

- GitHub  attaches the  public  part of  the key  directly  to your  repository
  instead of a personal  user account, and the private part  of the key remains
  on your server.

  #+cindex:write access
  #+cindex:admin access
  #+cindex:access, write, admin
  #+cindex:collaborator
- Deploy keys with write access can perform the same actions as an organization
  member with admin access, or a collaborator on a personal repository.

***** Pros
- Anyone with access to the repository and server has the ability to deploy the
  project.
- Users don't have to change their local SSH settings.
- Deploy keys are read-only by default, but you can give them write access when
  adding them to a repository.

***** Cons
- Deploy keys only grant access to a single repository. More complex projects
  may have many repositories to pull to the same server.
- Deploy keys are usually not protected  by a passphrase, making the key easily
  accessible if the server is compromised.

***** Setup
[[https://docs.github.com/en/free-pro-team@latest/developers/overview/managing-deploy-keys#setup-2][Setup guide]]

**** Machine Users

#+cindex:machine user
#+cindex:automation
If your  server needs  to access  multiple repositories, you  can create  a new
GitHub  account  and attach  an  SSH  key that  will  be  used exclusively  for
automation. Since this GitHub  account won't be used by a  human, it's called a
"machine user"

#+cindex:collaborator
#+cindex:outside collaborator
#+cindex:team
You can add the machine user as:
- a collaborator on a personal repository (granting read and write access)
- an outside collaborator on an  organization repository (granting read, write,
  or admin access)
- to a team with access to the  repositories it needs to automate (granting the
  permissions of the team).

***** Pros
- Anyone with access to the repository and server has the ability to deploy the
  project.
- No (human) users need to change their local SSH settings.
- Multiple keys are not needed; one per server is adequate.

***** Cons
- Only organizations can  restrict machine users to  read-only access. Personal
  repositories always grant collaborators read/write access.
- Machine  user  keys,  like  deploy  keys, are  usually  not  protected  by  a
  passphrase.

***** Setup
[[https://docs.github.com/en/free-pro-team@latest/developers/overview/managing-deploy-keys#setup-3][Setup guide]]

*** Viewing Deployment History

#+cindex:deployments, view
View current and previous deployments for your repository.

#+cindex:deployments, deliver
#+cindex:GitHub Actions
You can deliver deployments through:
- GitHub Actions and environments
- with the REST API and third party apps

To view  current and past deployments,  click Environments on the  home page of
your repository.

*** Using SSH Agent Forwarding
To simplify  deploying to  a server,  you can  set up  SSH agent  forwarding to
securely use local SSH  keys. It allows you to use your  local SSH keys instead
of leaving keys (without passphrases!) sitting on your server.

You need to be familiar with ~ssh-agent~.

  - It's a program that runs in the  background and keeps your key loaded into
   memory, so that you don't need to enter your passphrase every time you need
   to use the key.

  - you can choose to let servers access your local ~ssh-agent~ as if they were
    already running on the server.

  - This is sort  of like asking a  friend to enter their password  so that you
    can use their computer.

See [[http://www.unixwiz.net/techtips/ssh-agent-forwarding.html][Steve Friedl's Tech Tips guide]]

**** Setting up SSH agent forwarding

***** Ensure that your own SSH key is set up and working
See [[https://docs.github.com/en/free-pro-team@latest/articles/generating-ssh-keys][our guide on generating SSH keys]]

You can test that your local key works by entering:

: $ ssh -T git@github.com
: # Attempt to SSH in to github
: > Hi username! You've successfully authenticated, but GitHub does not provide
: > shell access.

[[shell:ssh -T git@github.com][Test local key]]

***** Now set up SSH to allow agent forwarding to your server.

1. Open up the file at ~~/.ssh/config~

2. Enter the following text into the file:
   : Host example.com [your server's domain name]
   :   ForwardAgent yes

   - Warning ::  You may be  tempted to  use a wildcard  like =Host *=  to just
     apply this setting to all SSH  connections. That's not really a good idea,
     as you'd be  sharing your local SSH  keys with every server  you SSH into.
     They won't have  direct access to the  keys, but they will be  able to use
     them as you while the connection is established

     You should  only add  servers you trust  and that you  intend to  use with
     agent forwarding.

**** Testing SSH agent forwarding

To test  that agent forwarding  is working with your  server, you can  SSH into
your server and run  ~ssh -T git@github.com~ once more. If  all is well, you'll
get back the same prompt as you did locally.

If you're  unsure if your  local key  is being used,  you can also  inspect the
=SSH_AUTH_SOCK= variable on your server:

: $ echo "$SSH_AUTH_SOCK"
: # Print out the SSH_AUTH_SOCK variable
: > /tmp/ssh-4hNGMk8AZX/agent.79453

If the variable is not set, it means that agent forwarding is not working.

**** Troubleshooting SSH agent forwarding
[[https://docs.github.com/en/free-pro-team@latest/developers/overview/using-ssh-agent-forwarding#troubleshooting-ssh-agent-forwarding][See guide]]

*** Secret Scanning

*** Replacing GitHub Services

*** GitHib Developer Program

** Apps
 You can automate and streamline your workflow by building your own apps.
*** Getting Started with Apps
 Learn about building apps and setting up your development environment.
**** About Apps
 Apps on GitHub allow you to
 - automate and
 - improve your workflow.

 GitHub Apps are the officially recommended way to integrate with GitHub because
 they offer much more granular permissions  to access data. GitHub supports both
 - OAuth Apps and
 - GitHub Apps.

***** GitHub Apps
 GitHub Apps are first-class actors within GitHub.  A GitHub App acts on its own
 behalf, taking actions via the API directly using its own identity, which means
 you don't need to maintain a bot or service account as a separate user.

 GitHub Apps  are applications that  need to be  hosted somewhere. To  install a
 GitHub App, you  must be an organization  owner or have admin  permissions in a
 repository. By  default, only  organization owners can  manage the  settings of
 GitHub Apps in an organization.

 To improve  your workflow, you can  create a GitHub App  that contains multiple
 scripts  or an  entire application,  and then  connect that  app to  many other
 tools.
 - For example,  you can connect  GitHub Apps  to GitHub, Slack,  other in-house
   apps you may have, email programs, or other APIs.

 GitHub Apps  can be installed directly  on organizations and user  accounts and
 granted access to  specific repositories. They come with  built-in webhooks and
 narrow, specific permissions.  When you set up your GitHub  App, you can select
 the repositories you want it to access.

 - For example, you can set up an app called MyGitHub that writes issues in the
   octocat repository and only the octocat repository.

 For a walkthrough of the process of building a GitHub App, see:
 - [[https://docs.github.com/en/free-pro-team@latest/apps/building-your-first-github-app][Building Your First GitHub App]]


 - A user or organization can own up to 100 GitHub Apps.
 - A GitHub App should take actions independent of a user
 - Make sure the GitHub App integrates with specific repositories.
 - The GitHub App should connect to a personal account or an organization.
 - Don't expect the GitHub App to know and do everything a user can.
 - Don't use a GitHub App if you just  need a "Login with GitHub" service. But a
   GitHub App can  use a user identification  flow to log users in  and do other
   things.
 - Don't build  a GitHub App  if you only  want to act as  a GitHub user  and do
   everything that user can do.


***** About OAuth Apps
 An OAuth App  uses GitHub as an  identity provider to authenticate  as the user
 who  grants access  to the  app. This  means when  a user  grants an  OAuth App
 access, they grant permissions to all repositories they have access to in their
 account, and  also to  any organizations  they belong  to that  haven't blocked
 third-party access.

 Building  an OAuth  App is  a  good option  if  you are  creating more  complex
 processes  than  a  simple  script  can   handle.  Note  that  OAuth  Apps  are
 applications that need to be hosted somewhere.

 To create an OAuth App, see:
 - [[https://docs.github.com/en/free-pro-team@latest/apps/building-oauth-apps/creating-an-oauth-app][Creating an OAuth App]]
 - [[https://docs.github.com/en/free-pro-team@latest/rest/guides/basics-of-authentication#registering-your-app][Registering your app]]

 - A user or organization can own up to 100 OAuth apps.
 - An OAuth App should always act as the authenticated GitHub user across all of
   GitHub
 - An OAuth App  can be used as  an identity provider by enabling  a "Login with
   GitHub" for the authenticated user.
 - Don't build  an OAuth App  if you  want your application  to act on  a single
   repository. With  the repo  OAuth scope,  OAuth Apps  can act  on all  of the
   authenticated user's repositories.
 - Don't build an OAuth  App to act as an application for  your team or company.
   OAuth Apps authenticate as a single userDon't build an OAuth App to act as an
   application for  your team or  company. OAuth  Apps authenticate as  a single
   user.

***** Personal Access Token
 A personal access  token is a string of characters  that functions similarly to
 an OAuth token in  that you can specify its permissions  via scopes. A personal
 access token is also  similar to a password, but you can have  many of them and
 you can revoke access to each one at any time.

 As  an example,  you  can enable  a  personal  access token  to  write to  your
 repositories. If then you run a cURL  command or write a script that creates an
 issue  in  your  repository,  you  would pass  the  personal  access  token  to
 authenticate.  You  can store  the  personal  access  token as  an  environment
 variable to avoid typing it every time you use it.

 - Remember to use this token to represent yourself only.
 - You can perform one-off cURL requests.
 - You can run personal scripts.


***** Determining which integration to build
 You need to  determine the best way to access,  authenticate, and interact with
 the GitHub APIs.

 - Only as me?
   - Yes
     - Access everything?
       - Yes
	 - Simple?
	   - Yes
	     - Personal Access Token
	   - No
	     - OAuth App
       - No
	 - GitHub App
   - No; it will act like an application
     - Act as the App?
       - Yes
	 - GitHub App
       - No
	 - Access everything?
	   - Yes
	     - OAuth App
	   - No
	     - GitHub App

**** Differences between GitHub Apps and OAuth Apps
 - An OAuth App acts as a GitHub user, whereas
 - a GitHub App uses its own identity when installed on an organization or on
   repositories within an organization.

***** Who can install GitHub Apps and authorize OAuth Apps?
 You can install GitHub Apps in  your personal account or organizations you own.
 By default, only organization owners can  manage the settings of GitHub Apps in
 an organization. You can install a GitHub App on your personal repository.

 Installation  access tokens  are  limited to  specified  repositories with  the
 permissions chosen by the creator of the app.

 By contrast, users authorize OAuth Apps, which gives the app the ability to act
 as the  authenticated user. You  can authorize an OAuth  app to have  access to
 resources.

 - For example, you can authorize an  OAuth App that finds all notifications for
   the authenticated user. You can always revoke permissions from an OAuth App.

 An OAuth access token is limited via scopes.

***** What can GitHub Apps and OAuth Apps access?
 Account owners can use  a GitHub App in one account  without granting access to
 another.

 An authorized OAuth App has access to all of the user's or organization owner's
 accessible resources.

***** Token-based identification
 A GitHub App  can request an installation  access token by using  a private key
 with a JSON web token format out-of-band.

 An  installation token  identifies the  app  as the  GitHub Apps  bot, such  as
 @jenkins-bot.

 Installation  tokens expire  after a  predefined  amount of  time (currently  1
 hour).

 An OAuth app can exchange a request  token for an access token after a redirect
 via a web request.

 An access  token identifies the app  as the user  who granted the token  to the
 app, such as @octocat.

 OAuth tokens remain active until they're revoked by the customer.

***** Requesting permission levels for resources
 Unlike OAuth  apps, GitHub Apps  have targeted  permissions that allow  them to
 request access only to what they need.

 OAuth Apps can't use granular permissions.

**** Understand the Different Methods of Authentication
 GitHub Apps  primarily use  a token-based authentication  that expires  after a
 short amount of time, providing more security than an OAuth token that does not
 expire. It’s  important to understand  the different methods  of authentication
 available to you and when you need to use them:

 - A JSON Web Token (JWT) ::

    authenticates as  the GitHub App. For  example, you can authenticate  with a
   JWT to  fetch application  installation details  or exchange  the JWT  for an
   installation access token.

 - An installation access token ::

   authenticates  as a  specific installation  of your  GitHub App  (also called
   server-to-server  requests).  For  example,  you  can  authenticate  with  an
   installation access  token to  open an  issue or provide  feedback on  a pull
   request.

   The most common scenario is to  authenticate as a specific installation using
   an installation access token.

 - An OAuth access token ::

   can authenticate  as a user  of your  GitHub App (also  called user-to-server
   requests). For example, you can use  an OAuth access token to authenticate as
   a user when a GitHub App needs to verify a user’s identity or act on a user’s
   behalf.

**** Setting up your development environment to create a GitHub App
 Learn the foundations for extending and building new GitHub Apps.

***** Introduction
 This guide will walk through the steps needed to configure a GitHub App and run
 it on a server.

 - [[https://docs.github.com/en/free-pro-team@latest/developers/apps/setting-up-your-development-environment-to-create-a-github-app][Guide to configure a GitHub App]]

 GitHub Apps require  some setup steps to manage webhook  events and connect the
 app registration  on GitHub to  your code.  The app in  this guide serves  as a
 foundation that you can use to extend and build new GitHub Apps.

 By the end of this guide:
 - you'll have registered a GitHub App
 - set up a web server to receive webhook events
 - You'll learn how  to use a tool  called Smee to capture  webhook payloads and
   forward them to your local development environment
 - The template app  you'll configure in this section won't  do anything special
   yet, but it will  serve as a framework you can use to  start writing app code
   using the API


 After completing  this project  you will  understand how  to authenticate  as a
 GitHub  App and  an  installation,  and how  those  authentication methods  are
 different.

*** Building GitHub Apps
 You can build GitHub Apps for personal or public use. Learn how to register and
 set up permissions and authentication options for GitHub Apps.

 - [[https://docs.github.com/en/free-pro-team@latest/developers/apps/building-github-apps][Build GitHub Apps]]

*** Managing GitHub Apps
*** Building OAuth Apps
 You can build OAuth Apps for personal  or public use. Learn how to register and
 set up permissions and authorization options for OAuth Apps.

 - [[https://docs.github.com/en/free-pro-team@latest/developers/apps/building-oauth-apps][Build OAuth Apps]]
**** Create an OAuth App
 You can create and  register an OAuth App under your  personal account or under
 any organization you have administrative access to.

 1. Settings
 2. Developer Settings
 3. OAuth Apps
 4. New OAuth App
 5. "Application name"
 6. "Homepage URL"
    : http://localhost:3000
 7. Description
 8. Authorization Callback URL
    : http://localhost:3000/callback
 9. Register

**** Authorize an OAuth App
 You can enable other users to authorize your OAuth App.

 GitHub's OAuth  implementation supports:
 - the standard [[https://tools.ietf.org/html/rfc6749#section-4.1][Authorization  Code Grant]] type and
 - the OAuth 2.0 *Device Authorization Grant* for apps that don't have access to
   a web browser.

 To authorize your  OAuth app, consider which authorization flow  best fits your
 app.

 - web application flow :: Used to authorize users for standard OAuth apps that
   run in the browser.
 - device flow :: Used for headless apps, such as CLI tools.
 - implicit grant type :: Not supported

***** Web Application Flow
 The web application flow to authorize users for your app is:

 1. Users are redirected to request their GitHub identity

    : GET https://github.com/login/oauth/authorize

    - Parameters
      - =client_id= :: (string) *Required* The client ID you received from
	GitHub when you registered.

      - =redirect_url= :: (string) *Optional* The  URL in your application where
	users will be sent after authorization.

	The =redirect_uri= parameter is optional.
	- If left out, GitHub will redirect users to the callback URL configured
          in the OAuth Application settings.
	- If provided, the  redirect URL's host and port must  exactly match the
          callback URL.
	- The redirect URL's path must  reference a subdirectory of the callback
          URL.

	: CALLBACK: http://example.com/path
	: GOOD: http://example.com/path
	: GOOD: http://example.com/path/subdir/other

	Localhost redirect urls
	- The optional =redirect_uri= parameter can also be used for localhost
          URLs

	- If the  application specifies a localhost  URL and a port,  then after
          authorizing the application  users will be redirected  to the provided
          URL and port.

	- The =redirect_uri=  does not need to  match the port specified  in the
          callback url for the app.

	- For  the   http://localhost/path  callback  URL,  you   can  use  this
          =redirect_uri=:
	  : http://localhost:1234/path

      - =login= ::  (string) Suggests a specific  account to use for  signing in
	and authorizing the app.

      - =scope= :: (string) A space-delimited list of scopes.

      - =state= :: (string) An unguessable random  string. It is used to protect
	against cross-site request forgery attacks.

      - =allow_signup= :: (string) Whether or  not unauthenticated users will be
	offered  an option  to sign  up for  GitHub during  the OAuth  flow. The
	default is true. Use false when a policy prohibits signups.

 2. Users are redirected back to your site by GitHub

    If the user accepts your request, GitHub  redirects back to your site with a
    temporary code in a code parameter as  well as the state you provided in the
    previous step in a state parameter.  The temporary code will expire after 10
    minutes. If the states don't match,  then a third party created the request,
    and you should abort the process.

    Exchange this code for an access token:

    : POST https://github.com/login/oauth/access_token

    - Parameters
      - =client_id=  :: (string)  *Required*  The client  ID  you received  from
	GitHub for your GitHub App.

      - =client_secret= ::  (string) *Required*  The client secret  you received
	from GitHub for your GitHub App.

      - =code= ::  (string) *Required* The  code you  received as a  response to
	Step 1.

      - =redirect_uri= :: (string) *Required* The  URL in your application where
	users are sent after authorization.

      - =state= :: (string) The unguessable random string you provided in
	Step 1.

    - Response

      By default, the response takes the following form:

      : access_token=e72e16c7e42f292c6912e7710c838347ae178b4a&token_type=bearer

      You can  also receive the  content in  different formats depending  on the
      Accept header:

      #+begin_example
	Accept: application/json
	{
		"access_token":"e72e16c7e42f292c6912e7710c838347ae178b4a",
		"scope":"repo,gist",
		"token_type":"bearer"
	}

	Accept: application/xml
	<OAuth>
	  <token_type>bearer</token_type>
	  <scope>repo,gist</scope>
	  <access_token>e72e16c7e42f292c6912e7710c838347ae178b4a</access_token>
	</OAuth>
      #+end_example

 3. Your app accesses the API with the user's access token
 The access token allows you to make requests to the API on a behalf of a user.

 : Authorization: token OAUTH-TOKEN
 : GET https://api.github.com/user

 For example, in curl you can set the Authorization header like this:

 : curl -H "Authorization: token OAUTH-TOKEN" https://api.github.com/user

***** Device Flow
 The device flow allows you to authorize users for a headless app, such as a CLI
 tool or Git credential manager.

 - [[https://docs.github.com/en/free-pro-team@latest/developers/apps/authorizing-oauth-apps#device-flow][Device Flow]]
 - [[https://tools.ietf.org/html/rfc8628#section-3.5][OAuth 2.0 Device Authorization Grant]]

 1. Your  app  requests  device  and  user  verification  codes  and  gets  the
  authorization URL where the user will enter the user verification code.
  : POST https://github.com/login/device/code

   Your app must request a:
   - /user verification code/ and
   - /verification URL/ that the app will use to prompt the user to authenticate
     in the next step.
   - This request  also returns a /device  verification code/ that the  app must
     use to receive an access token and check the status of user authentication.

   - Input parameters
     - =client_id= :: (string) *Required* The client ID you received from GitHub
       for your app.

     - =scope= :: (string) The scope that your app is requesting access to.

   - Response
     #+begin_example
       {
	 "device_code": "3584d83530557fdd1f46af8289938c8ef79f9dc5",
	 "user_code": "WDJB-MJHT",
	 "verification_uri": "https://github.com/login/device",
	 "expires_in": 900,
	 "interval": 5
       }
     #+end_example

   - Response parameters
     - =device_code= :: (string)  The device verification code  is 40 characters
       and used to verify the device.

     - =user_code= ::  (string) The user  verification code is displayed  on the
       device  so the  user can  enter the  code in  a browser.  This code  is 8
       characters with a hyphen in the middle.

     - =verification_uri= :: The verification URL  where users need to enter the
       user_code
       : https://github.com/login/device

     - =expires_in= ::  (integer) The number  of seconds before  the device_code
       and user_code expire. The default is 900 seconds or 15 minutes.

     - =interval=  :: (integer)  The minimum  number of  seconds that  must pass
       before you can make a new access token request
       : POST https://github.com/login/oauth/access_token
       to complete the device authorization. 

 2. The app prompts the user to enter a user verification code at:
   : https://github.com/login/device
   Your device will show the user verification code and prompt the user to enter
    the code.

 3  The  app  polls for  the  user  authentication  status.  Once the  user  has
   authorized the  device, the app  will be  able to make  API calls with  a new
   access token.
   : POST https://github.com/login/oauth/access_token
   Your app  will make  device authorization  requests that  poll the  above uri
   until  the  device  and  user  codes expire  or  the  user  has  successfully
   authorized the  app with  a valid  user code.  The app  must use  the minimum
   polling interval retrieved in step 1 to avoid rate limit errors.

   The user must enter a valid code within 15 minutes (or 900 seconds). After 15
   minutes, you will need to request a new device authorization code with:
   : POST https://github.com/login/device/code
   Once the user has  authorized, the app will receive an  access token that can
   be used to make requests to the API on behalf of a user.

   - Input parameters
     - =client_id= :: (string) *Required* The client ID you received from GitHub
       for your OAuth App.
     - =device_code=  :: (string)  *Required* The  device verification  code you
       received from the:
       : POST https://github.com/login/device/code
       request.
     - =grant_type= :: (string) *Required* The grant type must be:
       : urn:ietf:params:oauth:grant-type:device_code

   - Response
     #+begin_example
       {
	"access_token": "e72e16c7e42f292c6912e7710c838347ae178b4a",
	 "token_type": "bearer",
	 "scope": "user"
       }
     #+end_example

   - Rate limits

     When a user submits the verification code  on the browser, there is a there
     is a rate limit of 50 submissions in an hour per application.

     If you make more than one access token request at:
     : POST https://github.com/login/oauth/access_token
     within the required minimum  timeframe between requests (=interval=) you'll
     hit the rate  limit and receive a =slow_down= error  response, which adds 5
     seconds to the last =interval=.

****** Error Codes for the Device Flow

  - [[https://docs.github.com/en/free-pro-team@latest/developers/apps/authorizing-oauth-apps#error-codes-for-the-device-flow][error codes]]

**** Scope of OAuth App
 Scopes  let you  specify exactly  what type  of access  you need.
 - Scopes limit access for  OAuth tokens.
 - They  do not  grant  any additional  permission beyond  that  which the  user
   already has.

 When setting up an  OAuth App on GitHub, requested scopes  are displayed to the
 user on the authorization form.

 If your OAuth  App doesn't have access to  a browser, such as a  CLI tool, then
 you don't need to specify a scope for users to authenticate to your app.

 Check  headers to  see what  OAuth scopes  you have,  and what  the API  action
 accepts:

 #+begin_example
   $ curl -H "Authorization: token OAUTH-TOKEN" https://api.github.com/users/codertocat -I
   HTTP/1.1 200 OK
   X-OAuth-Scopes: repo, user
   X-Accepted-OAuth-Scopes: user
 #+end_example

 : $ curl -H "Authorization: token $GITHUB_TOKEN" https://api.github.com/users/wlharvey4 -I
 : > X-OAuth-Scopes: admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, delete_repo, gist, notifications, repo, user, workflow, write:discussion

***** Available Scopes
 - [[https://docs.github.com/en/free-pro-team@latest/developers/apps/scopes-for-oauth-apps#available-scopes][available scopes]]

***** Request Scopes
 Your  OAuth App  can request  the scopes  in the  initial redirection.  You can
 specify multiple scopes by separating them with a space:

 #+begin_example
   https://github.com/login/oauth/authorize?
     client_id=...&
     scope=user%20public_repo
 #+end_example

***** Requested scopes and granted scopes
 The =scope= attribute lists scopes attached to the token that were granted by the
 user.

 Normally, these scopes will be identical  to what you requested.
 - However, users can edit their  scopes, effectively granting your application
   less access than you originally  requested.
 - It's important to handle  error cases where a user chooses  to grant you less
   access than you  originally requested. For example, applications  can warn or
   otherwise  communicate   with  their  users   that  they  will   see  reduced
   functionality or be unable to perform some actions.
 - Also, users  can edit  token scopes after  the OAuth flow is  completed.
 - You  should  be aware  of  this  possibility  and adjust  your  application's
   behavior accordingly.
 - Also, applications can  always send users back through the  flow again to get
   additional permission, but don’t forget that users can always say

**** Create a Custom Badge

*** Managing OAuth Apps
*** Guides
** Webhooks and Events
* REST API
You can  use the GitHub REST  API to create calls  to get the data  you need to
integrate with GitHub.

- [[https://docs.github.com/en/free-pro-team@latest/rest][REST API]]

: https://api.github.com
: Accept: application/vnd.github.v3+json

** REST API Overview
Learn  about resources,  libraries, previews  and troubleshooting  for GitHub's
REST API.
*** Resources in the REST API
Learn how to navigate the resources provided by the GitHub API.

This describes the resources that make up the official GitHub REST API.

**** Current Version
By default,  all requests to  https://api.github.com receive the v3  version of
the  REST API.  We encourage  you to  explicitly request  this version  via the
=Accept= header.

: Accept: application/vnd.github.v3+json

**** Schema
- All API  access is  over HTTPS.

- The API is accessed from  https://api.github.com.

- All data is sent and received as JSON.

- All timestamps return in ISO 8601 format:
  : YYYY-MM-DDTHH:MM:SSZ

- Summary representations

  When you  fetch a list  of resources, the response  includes a subset  of the
  attributes for  that resource.  This is the  "summary" representation  of the
  resource.

  Example:  When  you  get  a  list   of  repositories,  you  get  the  summary
  representation of each repository.

  : GET /orgs/octokit/repos

- Detailed representations

  When you  fetch an individual  resource, the response typically  includes all
  attributes for  that resource. This  is the "detailed" representation  of the
  resource.

  Example:  When  you  get  an  individual repository,  you  get  the  detailed
  representation of the repository.

  : GET /repos/octokit/octokit.rb

**** Authentication
There are two ways to authenticate through GitHub REST API.

***** Basic authentication

: $ curl -u "username" https://api.github.com

***** OAuth2 token (sent in a header)

: $ curl -H "Authorization: token OAUTH-TOKEN" https://api.github.com

OAuth2 tokens can  be acquired using the /web application  flow/ for production
applications.

**** Parameters
Many API methods take optional parameters.

- For =GET= requests, any parameters not specified as a segment in the path can
  be passed as an HTTP query string parameter:

  : $ curl -i "https://api.github.com/repos/vmg/redcarpet/issues?state=closed"

- For =POST=, =PATCH=, =PUT=, and =DELETE= requests, parameters not included in
  the   URL   should   be   encoded   as  JSON   with   a   =Content-Type=   of
  'application/json':

  : $ curl -i -u username -d '{"scopes":["public_repo"]}' https://api.github.com/authorizations

**** Root Endpoint
You can  issue a =GET=  request to  the root endpoint  to get all  the endpoint
categories that the REST API supports:

: $ curl -u username:token https://api.github.com

**** HTTP Redirects
API v3 uses HTTP redirection where  appropriate. Clients should assume that any
request may  result in a redirection.  Receiving an HTTP redirection  is not an
error and clients  should follow that redirect.
- Redirect responses will have a =Location= header field which contains the URI
  of the resource to which the client should repeat the requests.

- Status Codes
  - 301 :: Permanent redirection.

  - 302 :: Temporary redirection.

  - 307 :: Ditto

**** HTTP Verbs
Where possible, API v3 strives to use appropriate HTTP verbs for each action.

- Verbs
  - =HEAD= :: Can be issued against any resource to get just the HTTP header info.
  - =GET= :: Used for retrieving resources.
  - =POST= :: Used for creating resources.
  - =PATCH= :: Used for updating resources with partial JSON data.
  - =PUT= :: Used for replacing resources or collections.
  - =DELETE= :: Used for deleting resources.

**** Pagination
Requests that return  multiple items will be paginated to  30 items by default.

- parameters
  - =page= :: You can specify further pages with the =page= parameter.

  - =per_page= :: For some resources, you can also set a custom page size up to
    100 with the =per_page= parameter.

    Note that  for technical reasons  not all endpoints respect  the =per_page=
    parameter, see =events= for example.

  : $ curl 'https://api.github.com/user/repos?page=2&per_page=100'

- cursor-based pagination
  - Some endpoints use cursor-based pagination.

  - A cursor is a string that points to a location in the result set.

  - With cursor-based pagination,  there is no fixed concept of  "pages" in the
    result set, so you can't navigate to a specific page.

  - Instead,  you  can traverse  the  results  by  using  the before  or  after
    parameters.

  - See guide on [[https://docs.github.com/en/free-pro-team@latest/guides/traversing-with-pagination][Traversing with Pagination]].

**** Link Header
- [[https://docs.github.com/en/free-pro-team@latest/rest/overview/resources-in-the-rest-api#link-header][Link Header]]

**** Rate Limiting
- [[https://docs.github.com/en/free-pro-team@latest/rest/overview/resources-in-the-rest-api#rate-limiting][Rate Limiting]]

**** User Agent Required
All API  requests MUST include  a valid  =User-Agent= header. Requests  with no
=User-Agent=  header will  be rejected.
  - We request  that you  use your  GitHub username, or
  - the name of your application, for  the =User-Agent= header value.
  - This allows us to contact you if there are problems.

: User-Agent: Awesome-Octocat-App

~cURL~ sends a valid =User-Agent= header by default

**** Conditional requests
Most  responses   return  an  =ETag=   header.

Many responses also return a =Last-Modified=  header.

You can use  the values of these  headers to make subsequent  requests to those
resources   using   the:
- =If-None-Match=   and
  : $ curl -i https://api.github.com/user -H 'If-None-Match: "644b5b0155e6404a9cc4bd9d8b1ae730"'
- =If-Modified-Since=
  : $ curl -i https://api.github.com/user -H "If-Modified-Since: Thu, 05 Jul 2012 15:31:30 GMT"
headers, respectively.

If the resource has not changed, the server will return a =304 Not Modified=.

Making  a conditional  request  and receiving  a 304  response  does not  count
against your =Rate Limit=, so we encourage you to use it whenever possible.

**** Cross origin resource sharing
The API  supports Cross Origin Resource  Sharing (CORS) for AJAX  requests from
any origin.

**** JSON-P callbacks
You can  send a  =?callback= parameter to  any =GET= call  to have  the results
wrapped in a JSON function. This is  typically used when browsers want to embed
GitHub content in web pages by getting around cross domain issues. The response
includes the same data output as the regular API, plus the relevant HTTP Header
information.

- [[https://docs.github.com/en/free-pro-team@latest/rest/overview/resources-in-the-rest-api#json-p-callbacks][JSON-P Callbacks]]

*** Media types
*** Other authentication methods
*** Troubleshooting
*** API previews
*** Libraries
- [[https://docs.github.com/en/free-pro-team@latest/rest/overview/libraries][Libraries]]

- Ruby :: [[https://github.com/octokit/octokit.rb][octokit.rb]]

- JavaScript ::  [[https://github.com/octokit/rest.js][octokit/rest.js]]

**** Third Party Libraries
- [[https://docs.github.com/en/free-pro-team@latest/rest/overview/libraries#third-party-libraries][Third Party Libraries]]

- Emacs Lisp :: [[https://github.com/sigma/gh.el][gh.el]]

- JavaScript ::
  - NodeJS GitHub library :: [[https://github.com/pksunkara/octonode][pksunkara/octonode]]

  - gh3 client-side API v3 wrapper :: [[https://github.com/k33g/gh3][k33g/gh3]]

  - Github.js wrapper around the GitHub API :: [[https://github.com/michael/github][michael/github]]

  - Promise-Based CoffeeScript library for the Browser or NodeJS ::
    [[https://github.com/philschatz/github-client][philschatz/github-client]]

- Ocaml :: [[https://github.com/mirage/ocaml-github][ocaml-github]]

- Perl ::
  - Pithub :: [[https://github.com/plu/Pithub][plu/Pithub]]  [[http://metacpan.org/module/Pithub][Pithub CPAN]]

  - Net::Github :: [[https://github.com/fayland/perl-net-github][fayland/perl-net-github]]  [[https://metacpan.org/pod/Net::GitHub][Net:Github CPAN]]

- Shell :: [[https://github.com/whiteinge/ok.sh][ok.sh]]

*** OpenAPI description
*** Endpoints available for GitHub Apps
- [[https://docs.github.com/en/free-pro-team@latest/rest/overview/endpoints-available-for-github-apsp][Endpoints]]

** REST API Reference
- [[https://docs.github.com/en/free-pro-team@latest/rest/reference][REST API Reference]]

** REST API  Guides
Learn about getting  started with the REST API, authentication,  and how to use
the REST API for a variety of tasks.

- [[https://docs.github.com/en/free-pro-team@latest/rest/guides][REST API Guides]]

* Build Tools
:PROPERTIES:
:appendix: t
:custom_id: build-tools
:END:
** Makefile					:dependencies:env_vars:perl:
:PROPERTIES:
:appendix: t
:dependency1: make
:dependency2.0: AWS User account at https://aws.amazon.com
:dependency2.1: AWS cli v2 in PATH https://docs.aws.amazon.com/cli/index.html
:dependency2.2: See how to Install AWS CLI v2 at https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html
:dependency2.3: aws credentials: access token and secret access token stored in ~/.aws/credentials
:dependency2.4: AWS S3 buckets set up for serving a static web page
:dependency3: GitHub Account with personal access token stored in GITHUB_TOKEN
:dependency4: texinfo @6.7._
:dependency5: Emacs, Org-mode, Babel language 'shell' enabled
:env_var1: SYNC_ORG_TEMPLATE: holds the full path to this Template.org file
:env_var2: GITHUB_TOKEN: holds the GitHub personal access token
:env_var3: EDITOR: must hold a reference to a working emacsclient server
:env_var4: COLORS
:END:

#+pindex:Makefile
#+name:Makefile
#+header: :tangle Makefile
#+begin_src makefile

  ###############################################################################
  ### USER-DEPENDENT VARIABLES
  ### USE ENVIRONMENT VARIABLES WHENEVER POSSIBLE

  # NOTE: All environment variables need to be exported PRIOR to starting the
  # Emacs server as EDITOR in your shell startup files; otherwise, they will not
  # be available to Emacs.
  # When I moved from using Bash to Zsh, I inadvertently changed the order of
  # import, and started the Emacs server before importing, and caused a horrible
  # bug which caused the program to work on one computer but fail on another.

  # The absolute path to this Template file
  TEMPLATE := $(SYNC_ORG_TEMPLATE)


  ### TOOLS & RESOURCES
  # tools is a directory holding tangled scripts, such as cmprpl
  # resources is a directory holding static resources for the project
  # images is a directory holding jpg and png image files
  RESOURCES := resources
  TOOLS	    := $(RESOURCES)/tools
  IMAGES    := $(RESOURCES)/images
  CMPRPL    := $(TOOLS)/cmprpl

  # Use emacsclient as $EDITOR; make sure it is set in a shell startup file and
  # the server has been started.
  EMACS	  := $(EMACS)
  EDITOR  := $(EDITOR)

  # User’s personal GitHub token for authentication to GitHub
  # DO NOT HARD-CODE THIS VALUE
  GITHUB_TOKEN := $(GITHUB_TOKEN)

  # The AWS Command Line Interface (AWS CLI) is an open source tool
  # that enables you to interact with AWS services using commands in
  # your command-line shell.  It must be present on your system.  Run the 'make'
  # command 'install-aws-cli' to install it if you do not have it.  Be sure to
  # run 'aws configure' after installing it.  This will place your AWS
  # credentials into ~/.aws/credentials.
  AWS := aws
  S3  := $(AWS) s3
  CFD := $(AWS) cloudfront

  ### END OF USER-DEPENDENT VARIABLES
  ###############################################################################
  ### MAKE-GENERATED VARIABLES

  ### PROJ AND ORG
  # ORG is the name of this Org file with extension .org
  # PROJ is the project name---the Org file name without extension.

  ### NOTE: there can be only one Org file in the project directory;
  # so far this has not been a problem, but it might be.

  PWD  := $(shell pwd)
  ORG  := $(shell ls *.org)
  PROJ := $(basename $(ORG))

  ### NOTE: S is needed only for the Template file because of the way it is nested
  # one level deep in the Templates GitHub repo, which uses the plural form
  # of Templates, whereas this file uses the singular form, Template.  So when
  # the homepage link is updated, the curl command must be told to use the plural
  # form.	 This is obviously a hack only for my own use and can be removed once
  # I clean up this anomaly.

  ifeq ($(PROJ),$(basename $(notdir $(TEMPLATE))))
  S := s
  endif

  # The AWS S3 bucket to use to store the html source file; it is found at the
  # key #+bucket towards the beginning of the file and should include the appropriate
  # suffix (.com, .net, .org, etc)
  BUCKET       := $(shell $(EDITOR) --eval \
		 '(with-current-buffer (find-file-noselect "$(ORG)") \
		    (save-excursion \
		      (goto-char (point-min)) \
		      (re-search-forward "^\#[+]bucket:\\(.*\\)$$" nil t) \
		      (match-string-no-properties 1)))')
  S3_BUCKET    := s3://$(BUCKET)

  # Buckets set up to serve static web sites from S3 can use either http
  # or https protocols; some  http protocols will automatically redirect
  # to https;  however, some only use  http. I would like  to accomodate
  # both, and  so this code  finds the url's  that are in  my Cloudfront
  # account, which presumably will serve https.  If the url is not here,
  # then this must be set up to serve http instead.
  HTTP_S := $(shell $(CFD) list-distributions | perl -MJSON::PP -e \
	  '$$/=""; \
	   my @urls = (); \
	   my $$json=JSON::PP->new->decode(<STDIN>); \
	   for my $$item ( @{$$json->{"DistributionList"}{"Items"}} ) { \
		  push @urls, @{$$item->{"Aliases"}{"Items"}}; \
	   } \
	  my $$found = grep { /'$(BUCKET)'/ } @urls; \
	  print "http", ($$found ? "s" : "");')

  HTTPS_BUCKET := https://$(BUCKET)

  ### DIR, SRC
  # DIR is the .info name found at '#+texinfo_filename:<DIR>.info' (at
  # the bottom of this file in the export configuration settings)
  # without its extension, used as the INFO filename and the name of the
  # HTML export directory; this code uses the lowercased PROJ name if
  # there is no '#+texinfo_filename'.
  # SRC is HTML directory based upon the DIR name

  #DIR := $(shell $(EDITOR) --eval \
  #	'(with-current-buffer (find-file-noselect "$(ORG)") \
  #		(save-excursion \
  #		(goto-char (point-min)) \
  #		(re-search-forward "^\#[+]\\(?:texinfo_filename\\|TEXINFO_FILENAME\\):\\(.*\\).info$$" nil t) \
  #		(match-string-no-properties 1)))')

  DIR := $(shell sed -E -n "/^\#\+texinfo_filename/s/^.*:(.*)\.info$$/\1/p" $(ORG))
  ifeq ($(DIR),$(EMPTY))
	  DIR := $(shell echo $(PROJ) | tr "[:upper:]" "[:lower:]")
  endif

  SRC := $(DIR)/

  ### VERS: v1.2.34/
  # VERS is the version number of this Org document.
  # When sync is run after the version number has been updated, then VERS
  # picks up the newly-changed value.  VERS used to be staticly imbedded
  # when the Makefile was tangled, but it needs to be dynamic for
  # development.

  # QUERY: should this number be formatted like this, or should it be just the numbers?
  # The reason it includes them is the S3PROJ obtains the name from the S3 bucket, and
  # it includes them.  But it only includes them because I have made it so.  Not a good
  # reason just by itself.  The ending slash is not actually a part of the version, but
  # comes from the way the 'aws2 ls' command returns its values.	So VERS should probably
  # not include the trailing slash, although it doesn’t hurt anything.

  VERS := v$(shell $(EDITOR) --eval \
	  '(with-current-buffer (find-file-noselect "$(ORG)") \
		  (save-excursion \
		    (goto-char (point-min)) \
		    (re-search-forward "^\#[+]\\(?:macro\\|MACRO\\):version Version \\(\\(?:[[:digit:]]+[.]?\\)\\{3\\}\\)") \
		    (match-string-no-properties 1)))')/

  ### AWS
  # PROJ_LIST contains the list of projects currently uploaded to
  # the S3 bucket; each item contains the name of the project and its
  # current version.

  # Created function using elisp instead of the shell.
  # This variable contains an elisp list of strings of the form '("proj1-v1.2.3/" "proj2-v4.5.6/" ...)'
  # However, when it prints to the shell, the quotes are lost.
  # Need to make sure elisp's variable 'exec-path contains the proper $PATH instead of adding to 'exec-path.

  PROJ_LIST := $(shell $(EDITOR) --eval \
	  "(progn \
		  (require (quote seq)) (add-to-list (quote exec-path) (quote \"/usr/local/bin\")) \
		  (seq-map (lambda (s) (replace-regexp-in-string \"^\s+PRE \" \"\" s)) \
			  (seq-filter (lambda (s) (string-match-p (regexp-quote \" PRE \") s)) \
			  (process-lines \"$(AWS)\" \"s3\" \"ls\" \"$(S3_BUCKET)\"))))")

  ### S3PROJ
  # The name of the current project as obtained from S3: 'proj-v1.2.34/'
  # If there is no current project in the S3 bucket, then assign a value equal to
  # the Org project and version instead.  It is set to the project if found, and
  # NO if not found, then updated in the ifeq block below.
  S3PROJ := $(shell $(EDITOR) --eval \
		  '(let ((proj (seq-find (lambda (s) (string-match-p "$(DIR)" s)) (quote $(PROJ_LIST))))) \
		     (or proj (quote NO)))')

  ### PROJINS3
  # is used by make sync; this allows the index.html file to be generated the first
  # time the project is synced.  It is set to NO if this project is not currently in an
  # S3 bucket, and it is set to YES if it is.
  PROJINS3 :=

  ### S3VERS
  # The version of this project currently installed in the S3 bucket: 'v1.2.34/'
  # If there is no current version in the S3 bucket, then assign the version from
  # this Org file instead.
  S3VERS   :=

  # Update S3PROJ, S3VERS, and PROJINS3
  ifeq ($(S3PROJ), NO)
	  S3PROJ := $(DIR)-$(VERS)
	  S3VERS := $(VERS)
	  PROJINS3 := NO
  else
	  S3VERS := $(subst $(DIR)-,,$(S3PROJ))
	  PROJINS3 := YES
  endif

  ### GITHUB
  # USER is the current user's GitHub login name.

  # The user name used to be statically embedded into the Makefile
  # during tangle, but in an effort to make the Makefile dynamically
  # indepedent, dynamic code has replaced the static code.  The code
  # that placed the static name in the Makefile was a 'node' script that
  # ran in a separate Org process during tangle.	An unfortunate fact of
  # 'make' is that 'make' strips the quote marks from the string
  # obtained from the 'curl' command when the 'make shell' command
  # returns the string.	 This makes the string malformed JSON and
  # unparsable by most JSON parsers, including 'node’.	However,
  # 'perl'’s core module JSON::PP (but not JSON::XS) has facilities to
  # parse very malformed JSON strings.	Therefore, this dynamic code
  # uses 'perl' and the core module JSON::PP to parse the 'curl' string
  # into a 'perl' JSON object which can return the login name.	This
  # code should work with any version of 'perl' without having to
  # install any modules.

  USER	:= $(shell \
	    curl -sH "Authorization: token $(GITHUB_TOKEN)" https://api.github.com/user \
	    | \
	    perl -MJSON::PP -e \
		'$$/ = ""; \
		 my $$json = JSON::PP->new->loose->allow_barekey->decode(<STDIN>); \
		 print $$json->{login};' \
	    )
  SAVE		:= resources

  ### TEXINFO
  TEXI		:= $(PROJ).texi
  INFO		:= $(DIR).info
  INFOTN	:= $(shell $(EDITOR) --eval "(file-truename \"$(INFO)\")")
  PDF		:= $(PROJ).pdf
  INDEX		:= index.html
  HTML		:= $(DIR)/$(INDEX)
  DIR_OLD	:= $(DIR)-old

  ### AWS S3
  DST_OLD	:= $(S3_BUCKET)/$(S3PROJ)
  DST_NEW	:= $(S3_BUCKET)/$(DIR)-$(VERS)
  EXCL_INCL	:= --exclude "*" --include "*.html"
  INCL_IMAGES	:= --exclude "*" --include "*.jpg" --include "*.png"
  GRANTS	:= --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers
  S3SYNC	:= $(S3) sync --delete $(EXCL_INCL) $(SRC) $(DST_OLD) $(GRANTS)
  S3MOVE	:= $(S3) mv --recursive $(DST_OLD) $(DST_NEW) $(GRANTS)
  S3COPY	:= $(S3) cp $(INDEX) $(S3_BUCKET) $(GRANTS)
  S3REMOVE	:= $(S3) rm $(S3_BUCKET)/$(S3PROJ) --recursive
  S3IMAGESYNC	:= $(S3) sync $(INCL_IMAGES) $(IMAGES) $(S3_BUCKET)/$(IMAGES) $(GRANTS)

  ###############################################################################

  default: check texi info html pdf

  PHONY: default all check values boot \
	    texi info html pdf \
	    open-org open-texi open-html open-pdf \
	    clean dist-clean wiped-clean \
	    help sync update delete-proj \
	    install-aws-cli \
	    index-html upload-index-html

  values: check
	    @printf "$${BLUE}Values...$${CLEAR}\n"
	    @echo TEMPLATE:	$(TEMPLATE)
	    @echo EDITOR:	$(EDITOR)
	    @echo USER:		$(USER)
	    @echo PWD:		$(PWD)
	    @echo ORG:		$(ORG)
	    @echo TEXI:		$(TEXI)
	    @echo INFO:		$(INFO)
	    @ECHO INFOTN:	$(INFOTN)
	    @echo BUCKET:	$(BUCKET)
	    @echo PROJ:		$(PROJ) $S
	    @echo S3_BUCKET:	$(S3_BUCKET)
	    @echo HTTP_S:	$(HTTP_S)
	    @echo HTTPS_BUCKET:	$(HTTPS_BUCKET)
	    @echo VERS:		$(VERS)
	    @echo S3PROJ:	$(S3PROJ)
	    @echo S3VERS:	$(S3VERS)
	    @echo DIR:		$(DIR)
	    @echo DIR_OLD:	$(DIR_OLD)
	    @echo SRC:		$(SRC)
	    @echo DST_OLD:	$(DST_OLD)
	    @echo DST_NEW:	$(DST_NEW)
	    @echo PROJ_LIST:	"$(PROJ_LIST)"
	    @echo PROJINS3:	$(PROJINS3)

  check:
	    @printf "$${BLUE}Checking dependencies...$${CLEAR}\n"

	    @[[ -z $(BUCKET) ]] && \
	       { printf "$${RED}$(BUCKET) $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}BUCKET: $${GREEN}$(BUCKET)$${CLEAR}\n";

	    @[[ -z $${GITHUB_TOKEN} ]] && \
	       { printf "$${RED}GITHUB_TOKEN $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	       printf "$${CYAN}GITHUB_TOKEN: $${GREEN}SET$${CLEAR}\n";

	    @[[ (-d ~/.aws) && (-f ~/.aws/credentials) && (-f ~/.aws/config) ]] && \
	       printf "$${CYAN}AWS credentials and config: $${GREEN}SET$${CLEAR}\n" || \
	       { printf "$${RED}~/.aws 'credentials' and 'config' must be set.$${CLEAR}\n"; exit 1; }

	    @[[ "$(shell $(EDITOR) --eval '(member (quote texinfo) org-export-backends)')" = "(texinfo)" ]] && \
		  printf "$${CYAN}Texinfo backend: $${GREEN}INSTALLED.$${CLEAR}\n" || \
		  { printf "$${YELLOW}Texinfo backend:$${CLEAR} $${RED}NOT INSTALLED; it must be installed.$${CLEAR}\n"; exit 1; }

	    @[[ $(shell $(EDITOR) --eval '(symbol-value org-confirm-babel-evaluate)') == "t" ]] && \
		  { printf "$${YELLOW}org-confirm-babel-evaluate:$${CLEAR} $${RED}T; set to NIL.$${CLEAR}\n"; exit 1; } || \
		  printf "$${CYAN}org-confirm-babel-evaluate: $${GREEN}OFF.$${CLEAR}\n\n"

  open-org: $(ORG)
	    @$(EDITOR) -n $(ORG)
  $(ORG):
	    @echo 'THERE IS NO $(ORG) FILE!!!'
	    exit 1

  texi: $(TEXI)
  $(TEXI): $(ORG)
	   @echo Making TEXI...
	   @$(EDITOR) -u --eval \
		  "(with-current-buffer (find-file-noselect \"$(ORG)\" t) \
			  (save-excursion \
			  (org-texinfo-export-to-texinfo)))"
	   @echo Done making TEXI.
  open-texi: texi
	   @$(EDITOR) -n $(TEXI)

  info: $(INFO)
  $(INFO): $(TEXI)
	   @echo Making INFO...
	   @makeinfo -o $(INFO) $(TEXI)
	   @$(EDITOR) -u -eval \
		  "(when (get-buffer \"$(INFO)\") \
			  (with-current-buffer (get-buffer \"$(INFO)\") \
				  (revert-buffer t t t)))"
	   @echo Done making INFO.

  open-info: info
	   @$(EDITOR) -u -eval \
		  "(if (get-buffer \"*info*\") \
			  (with-current-buffer (get-buffer \"*info*\") \
				(when (not (string= \"(symbol-value (quote Info-current-file))\" \"$(INFOTN)\")) \
					(info \"$(INFOTN)\")) \
				(revert-buffer t t t)) \
		      (info \"$(INFOTN)\"))"

  html: $(HTML)
  $(HTML): $(TEXI)
	   @echo Making HTML INFO..
	   @makeinfo --html -o $(DIR) $(TEXI)
	   @echo Done making HTML.
	   $(CMPRPL) $(DIR) $(DIR_OLD)
  open-html: html
	   @open $(HTML)

  # If pdftexi2dvi produces an error, it may still produce a viable PDF;
  # therefore, use --tidy.  If it produces an error, try to link the PDF;
  # if it does not produce an error, the PDF will be added to the top dir
  # and there will be no attempt to link.
  pdf:	$(PDF)
  $(PDF): $(TEXI)
	  @echo Making PDF INFO...
	  @-pdftexi2dvi --quiet --build=tidy $(TEXI) || ln -s $(PROJ).t2d/pdf/build/$(PDF) $(PDF)
	  @echo Done making PDF.
  open-pdf:pdf
	   @open $(PDF)

  sync:   $(HTML)
	  @echo Syncing version $(VERS) onto $(S3VERS)...
	  $(S3SYNC)
	  $(S3IMAGESYNC)
	  @echo Done syncing.
	  [[ $(VERS) != $(S3VERS) ]] && { echo Moving...; $(S3MOVE); echo Done moving.;  make homepage; } || :
	  [[ $(PROJINS3) = "NO" ]] && make homepage || :

  # This is a target-specific variable for updating the “description”
  # key on the GitHub repo page with the current version number.  It
  # first makes a curl call to the GitHub project repo, finds the
  # “description” line, pulls out the description only (leaving the old
  # version) and then prints the value with the current version number.
  # This value is used by the “homepage:” target in the PATCH call.
  # This method is arguably harder to code but faster to run than using
  # Perl with the JSON::PP module.

  homepage: description = $(shell \
	  curl -s \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S | \
		  (perl -ne 'if (/^\s*\"description\":\s*\"(.*): v(?:(?:[[:digit:]]+[.]?){3})/) {print $$1}'))

  ### NOTE the use of the S variable at the end of PROJ; this is to handle
  # the singular case of the GitHub repo using the plural form, Templates
  # whereas the the Template.org file uses the singular form.
  homepage: $(ORG) upload-index-html
	    @echo Updating homepage...
	    @echo DESCRIPTION: $(description)
	    @echo VERS: $(VERS)
	    @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Content-Type: application/json" \
		  -X PATCH \
		  -d "{\"homepage\":\"$(HTTPS_BUCKET)/$(DIR)-$(VERS)\",\
		       \"description\":\"$(description): $(VERS)\"}" \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	    @echo Done updating homepage.

  delete-proj:
	  @echo Deleting project $(PROJ)...
	  @curl -i \
		  -H "Authorization: token $(GITHUB_TOKEN)" \
		  -H "Accept: application/vnd.github.v3+json" \
		  -X DELETE \
		  https://api.github.com/repos/$(USER)/$(PROJ)$S
	  @$(S3REMOVE)
	  @make dist-clean
	  @make upload-index-html
	  @$(EDITOR) -u --eval "(kill-buffer \"$(ORG)\")"
	  @rm -rf "../$(PROJ)"
	  @echo Done deleting project.

  index-html: $(INDEX)
  $(INDEX): $(ORG)
	  @echo making index.html...
	  $(EDITOR) --eval \
	  "(with-current-buffer (find-file-noselect \"$(ORG)\") \
		  (save-excursion \
		    (org-link-search \"#project-index-title\") \
		    (org-export-to-file (quote html) \"index.html\" nil t)))"
	  @echo Done making index.html.

  upload-index-html: $(INDEX)
	   @echo Uploading index.html...
	   $(S3COPY)
	   @echo Done uploading index.html

  install-aws-cli:
	    curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg" && \
	    sudo installer -pkg AWSCLIV2.pkg -target / && \
	    which aws && aws --version
	    rm -rf AWSCLIV2.pkg

  clean:
	  @echo Cleaning...
	    -@rm *~ 2>/dev/null
	    -@for file in *.??*; \
	    do \
		    ext=$${file#$(PROJ).}; \
		    [[ ! $${ext} =~ org|texi|info|pdf|html ]] && rm -rv $${file}; \
	    done

  dist-clean: clean
	  @echo Dist Cleaning...
	    @${EDITOR} -u --eval \
	      "(kill-buffer \"$(ORG)\")"
	    -@rm -rf *.{texi*,info*,html*,pdf*} $(DIR) $(TOOLS)
	    -@for dir in *; \
		do \
		    [ -d $$dir -a $$dir != "$(DIR_OLD)" -a $$dir != $(SAVE) ] && \
		    rm -vr $$dir; \
		done

  wipe-clean: dist-clean
	  @echo Wipe Clean...
	    -@rm -rf Makefile Readme.md $(DIR_OLD)
	    @git checkout Makefile README.md

  git-ready: dist-clean
	    git checkout Makefile
	    git checkout README.md
	    git status

  help:
	    @echo '"make boot" tangles all of the files in Template'
	    @echo '"make default" makes the .texi file, the .info file, \
	    the html files, and the .pdf file.'
	    @echo

	    @echo '"make check" checks for prerequistes'
	    @echo '"make values" runs check and prints variable values'
	    @echo

	    @echo '"make texi" makes the .texi file'
	    @echo '"make info" makes the .info file'
	    @echo '"make html" makes the html distribution in a subdirectory'
	    @echo '"make pdf" makes the .pdf file'
	    @echo

	    @echo '"make open-org" opens the ORG program using emacsclient for editing'
	    @echo '"make open-texi" opens the .texi file using emacsclient for review'
	    @echo '"make open-html" opens the distribution index.html file \
	    in the default web browser'
	    @echo '"make open-pdf" opens the .pdf file'
	    @echo

	    @echo '"make sync" syncs the html files in the AWS S3 bucket BUCKET; \
	    you must have your AWS S3 bucket name in the env var AWS_S3_BUCKET; \
	    You must have your AWS credentials installed in ~/.aws/credentials'
	    @echo

	    @echo '"make install-aws-cli" installs the "aws cli v2" command-line tools'
	    @echo 'You also need to run "aws configure" and supply your Access Key and Secret Access Key'
	    @echo

	    @echo '"make clean" removes the .texi, .info, and backup files ("*~")'
	    @echo '"make dist-clean" cleans, removes the html distribution, \
	    and removes the build directory'
	    @echo '"make wipe-clean" wipes clean the directory, including old directories'
	    @echo

	    @echo '"make delete-proj" deletes the project from the file system, GitHub and AWS'

#+end_src

*** TODO Next
1. The CloudFront configuration needs to be updated recognize the new version
   directory that is created as part of the ~sync~ operation.

2. Update the GitHub HOME website link for each new sync operation.

3. Store on GitHub a version of each other format upon a sync operation (i.e.,
   the INFO and PDF versions)

** Compare Replace

#+begin_comment
The following source code tangles all files during an export operation. This is
to  make  sure  the  ~cmprpl~  source code  exists  in  the  ~resources/tools/~
directory before running  the Makefile target =html=. It also  makes sure there
is a Makefile on an initial export. The following code is not exported.
#+end_comment

#+name:tangle-org-file
#+header: :exports results :eval yes :results silent
#+begin_src emacs-lisp
(org-babel-tangle-file (buffer-file-name))
#+end_src

The  AWS ~sync~  command  relies  upon time  stamps  to  determine whether  two
programs are identical or not, as  well as content.  If two otherwise identical
files have  different time stamps,  ~sync~ will  assume they are  different and
will  process the  newer.   However, the  ~texinfo~  ~makeinfo --html~  command
produces all  new files even  if some files  (or most files)  remain unchanged.
This  means that  all files  will be  uploaded to  the AWS  S3 bucket  on every
iteration, even though the majority of the files are actually unchanged.

The ~cmprpl~  source code attempts to  resolve the issue of  identical exported
code having different  time stamps, thus defeating the benefit  provided by the
~aws2 s3 sync~ command uploading only changed files.

This program makes sure that a generated HTML directory exists: =$DIR_NEW=.  If
it doesn’t, then it is in an improper state and the program stops with an error
message.

The  program then  checks  if  an old  directory  exists,  =$DIR_OLD=.  If  one
doesn’t,  then one  is  created by  copying the  current  new directory.   This
provides a baseline  for comparisons going forward.  The program  exits at that
point. It is very important that  the =$DIR_OLD= directory not be deleted going
forward.

Given  that =$DIR_OLD=  exists, the  program then  loops through  all files  in
=$DIR_NEW= and  compares them  to the  files in =$DIR_OLD=.   If the  files are
identical, the =$DIR_OLD= file replaces the =$DIR_NEW= file while retaining the
old time stamp (using the ~-p~ option of ~cp~. If a file is different, then the
=$DIR_NEW= file  replaces the =$DIR_OLD=  file, thus giving it  updated content
and  an updated  time stamp.   If the  file does  not exist  in the  =$DIR_OLD=
directory, then it is added.

The  program then  loops through  all of  the files  in the  old directory  and
deletes  any that  do not  exist in  the new  directory.  Now  both directories
should be in sync.

#+caption:Compare Replace program
#+name:cmprpl
#+header: :mkdirp t
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh :tangle resources/tools/cmprpl
  [[ $# -eq 2 ]] || { echo "ERROR: Incorrect command line arguments"; exit 1; }
  DIR_NEW=$1
  DIR_OLD=$2

  [[ -d $DIR_NEW ]] || { echo "ERROR: $DIR_NEW does not exist"; exit 1; }
  [[ -d $DIR_OLD ]] || { echo "CREATING: $DIR_OLD does not exist"; cp -a $DIR_NEW $DIR_OLD; exit 0; }

  for newfile in $DIR_NEW/*
  do
      oldfile=$DIR_OLD/$(basename $newfile)
      if [[ -e $oldfile ]]
      then
	 if cmp -s $newfile $oldfile
	 then
	     printf "${GREEN}copying OLD to NEW${CLEAR}: "
	     cp -vp $oldfile $newfile
	 else
	     printf "${PURPLE}copying NEW to OLD${CLEAR}: "
	     cp -vp $newfile $oldfile
	 fi
      else
	  printf "${BLUE}creating NEW in OLD${CLEAR}: "
	  cp -vp $newfile $oldfile
      fi
  done

  for oldfile in $DIR_OLD/*
  do
      newfile=$DIR_NEW/$(basename $oldfile)
      if [[ ! -e $newfile ]]
      then
	  printf "${RED}removing OLD${CLEAR}: "
	  rm -v $oldfile
      fi
  done
#+end_src


** Update Utility Commands
*** Get Parsed Org Tree
This function looks for an Org file in the present working directory, and if it
finds one returns  a parsed tree using  ~org-element-parse-buffer~.  It returns
=nil= if there is no Org file or if the found file is not in ~org-mode~.

#+name:get-parsed-org-tree
#+header: :results silent
#+begin_src emacs-lisp
(defun get-parsed-org-tree (&optional org-dir)
  "This function takes an optional directory name, changes to
that directory if given, otherwise uses the pwd, and finds an Org
file and returns its parsed tree, or nil if none found."
  (when org-dir
      (cd (file-name-as-directory org-dir)))
  (let ((buf (car-safe (find-file-noselect "*.org" nil nil t))))
    (if buf
	(with-current-buffer buf (org-element-parse-buffer))
      nil)))
#+end_src

*** Check for CID
This code  checks whether an  Org file contains  a =custom_id= of  a particular
value.  It accepts  a ~cid-value~ and an optional directory.   If the directory
is not given, then it defaults to the current directory.  If throws an error if
the directory does not exist.  It returns =nil= if the given directory does not
contain an Org file.   It returns =t= if the Org file  contains a node property
of   =custom_id=  and   value  ~cid-value~,   or   =nil=  if   not.   It   uses
~get-parsed-org-tree~.

#+name:org-tree-cid-p
#+header: :results silent
#+begin_src emacs-lisp
(defun org-tree-cid-p (cid-value &optional org-dir)
  "Check whether an org file contains a custom_id of CID"
  (let ((tree (get-parsed-org-tree org-dir)))
    (car (org-element-map tree 'property-drawer
	   (lambda (pd) (org-element-map (org-element-contents pd) 'node-property
			  (lambda (np)
			    (and
			     (string= "custom_id" (org-element-property :key np))
			     (string= cid-value (org-element-property :value np))))))
	   nil t))))
#+end_src

#+name:run-org-tree-cid-p
#+header: :var cid="build-tools"
#+header: :var dir="/usr/local/dev/programming/MasteringEmacs"
#+header: :var gpot=get-parsed-org-tree()
#+header: :var otcp=org-tree-cid-p()
#+header: :results value
#+header: :eval never-export
#+begin_src emacs-lisp
(org-tree-cid-p cid dir)
#+end_src

#+call: run-org-tree-cid-p(dir="/usr/local/dev/programming/MasteringEmacs")

** Bucket Index HTML
The bucket should contain a master ~index.html~  file that links to each of the
individual project  ~index.html~ files.  The  master ~index.html~ file  will be
placed at the root of  the bucket, ~https://<bucket-name>.com/~, and the bucket
must be set up to serve this ~index.html~ when the user hits the root.

*** Get Bucket Name
 This  code searches  for  the keyword-value  pair =bucket:<BUCKET-NAME>=  that
 should be  located towards the  beginning of the  file, and returns  the value
 =BUCKET-NAME= or nil if not found.

#+name: get-bucket-name
#+header: :results value
#+begin_src emacs-lisp
   (save-excursion
     (goto-char (point-min))
     (re-search-forward "^#\\+bucket:\\s*?\\(.*\\)$" nil t)
     (match-string-no-properties 1))
#+end_src

For some reason, ~get-bucket-name~ does not  work when called from the headline
[[#project-index-links][=Links for  bucket=]] below  when creating  =index.html=, even  if it  returns as
~(prin1 ...)~ and is  set up to ~:return output~; the  call receives =nil=. The
following code from ~bucket-name~, however, works. I don't know why.

#+name: bucket-name
#+header: :results output
#+header: :var bucket-name=get-bucket-name()
#+begin_src emacs-lisp
(prin1 bucket-name)
#+end_src

*** Bucket HTTPS URL
This  code calls  ~get-bucket-name~ and  returns the  value returned  as a  URL
string or nil.

#+name: bucket-https-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "https://" b)
#+end_src

*** S3 Bucket URL
This code calls ~get-bucket-name~ and returns the AWS S3 bucket url.

#+name: s3-bucket-url
#+header: :results value
#+header: :var b=get-bucket-name()
#+begin_src emacs-lisp
(concat "s3://" b)
#+end_src

*** Bucket Projects List
This code uses the ~s3-bucket-url~ result to obtain the list of projects in the
bucket.  It does  this by calling the  AWS S3 high-level command  ~ls~ and then
removing the  =PRE= string in  each result.  The result  that is returned  is a
single  string that  can be  separated into  individual links  by breaking  the
string on spaces.

#+name: bucket-projects-list
#+header: :results output
#+header: :var bucket=s3-bucket-url()
#+begin_src sh
/usr/local/bin/aws s3 ls ${bucket} | sed -ne 's/^.*PRE //p'
#+end_src

*** Bucket Project Links
This code  uses the result  from ~bucket-projects-list~ to create  an unordered
list of  links written to  bucket projects, written  in Org-mode syntax.  It is
executed by a =#+call:= in [[*Bucket Index][*Bucket  Index]] during an HTML export of that subtree
to a file called =index.html=.

#+name: bucket-project-links
#+header: :var b-url=bucket-https-url()
#+header: :var projects=bucket-projects-list()
#+header: :results output raw
#+begin_src emacs-lisp
(seq-do (lambda (u) (princ (format "- [[%s/%sindex.html][~%s~]]
" b-url u u))) (split-string projects))
#+end_src

*** Bucket Index
    :PROPERTIES:
    :custom_id: project-index-title
    :export_file_name: index.html
    :export_subtitle: {{{version}}} created {{{upload-date}}}
    :END:
#+html_doctype: html5
#+options: toc:nil html5-fancy:t

#+html: <hr>

**** Links for bucket call_bucket-name()
     :PROPERTIES:
     :unnumbered: t
     :custom_id: project-index-links
     :END:

#+call: bucket-project-links()
** Project Readme
This adds the README.md template to a project. It should be customized uniquely
for the project.

#+name:project-readme
#+header: :tangle README.md
#+begin_src markdown
# TITLE
## Subtitle
## Author
## Date
## Version
# ABSTRACT
This is the Org Template file.	It is the parent of all other Org Info blogs,
and provides the source code for processing them in various different ways.
# INTRODUCTION
# CHAPTER
## Section
### Subsection
#+end_src

** Boot Template
:PROPERTIES:
:dependency1: EMACS:=:/Applications/MacPorts/Emacs.app/Contents/MacOS/Emacs or similar
:dependency2: EDITOR:=:emacsclient
:dependency3: =SYNC_ORG_TEMPLATE= defined as $DEV/Templates/Org/Template.org
:END:
Although running the command ~org-babel-tangle~ (=C-c C-v t=) from within Emacs
will install  everything, it would  be nice to have  a simple Makefile  that is
downloaded with this  file that could be  invoked to do the  same thing without
starting Emacs and Org-mode and keying in the ~org-babel-tangle~ command.  This
little Makefile should be stored on  GitHub along with the ~Template.org~ file.
When  the source  is extracted  to a  directory, then  running this  Makefile's
default rule  as simply ~make~  will extract the ~preprocess.el~  script, which
updates  =DEV= and  then  extracts the  full Makefile.   Because  this file  is
tangled along with the full Makefile, it simply gets tacked onto the end of the
big Makefile as an additional rule.   Now, running ~make~ runs the default rule
from the  main Makefile, which is  to extract everything, then  export to TEXI,
INFO, HTML, and PDF forms.

It is assumed that an Emacs server is running, and that the $EDITOR environment
variable is set to use ~emacsclient~.

#+name:boot-template
#+header: :tangle Makefile
#+begin_src makefile
  boot:
	  $(EDITOR) -u --eval \
		  "(with-current-buffer (car (find-file-noselect \"./*.org\" nil nil t)) \
			  (goto-char (point-min)) \
			  (re-search-forward \"^#[+]name:preprocess.el$$\") \
			  (org-babel-tangle (quote (4))) \
			  (save-buffer) \
			  (kill-buffer))" \
	  --eval \
		  "(let ((rsrcdir \"resources\") \
			 (subdirs (list \"tools\" \"images\"))) \
		     (mkdir rsrcdir t) \
		     (dolist (subdir subdirs) (mkdir (concat rsrcdir \"/\" subdir) t)))"
	  ./resources/tools/preprocess.el
#+end_src

** Preprocess Env Vars
The environment variable DEV can be  in different locations and will be spelled
differently based  on how the  local machine is set  up.  For instance,  on one
system,  it will  be at  ~$HOME/Dev~  while in  another  system it  will be  at
~/usr/local/dev~.  However, the =:tangle= keyword  does not expand variables in
the form ~${DEV}~,  but rather requires absolute  paths, like ~/usr/local/dev~.
Therefore, this program works like a preprocessor for environment variables set
up  as part  of  =:tangle= lines,  changing them  to  their system  environment
variable values prior to tangling.  It lives in the ~resources/tools~ directory.

#+name:preprocess.el
#+header: :mkdirp t
#+header: :tangle resources/tools/preprocess.el
#+header: :shebang "#!/opt/local/bin/emacs -Q --script"
#+begin_src emacs-lisp
  (with-current-buffer (car (find-file-noselect "./*.org" nil nil t))
    (save-excursion
    (goto-char (point-min))
    (let ((re-search-str "\\(?::tangle\\|load-file \\(?:[\\]*\\)?[\"]\\)\s*\\(.*?/[dD]ev\\)/")
          (dev (getenv "DEV")))
      (while
              (re-search-forward re-search-str nil t)
              (replace-match dev t nil nil 1)))
    (save-buffer)
    (require 'org)
    (org-babel-tangle)))
#+end_src

** Samples
#+begin_comment
(cd "~/Dev/Emacs/MasteringEmacs/")
"/Users/pine/Dev/Emacs/MasteringEmacs/"

(defun add-bucket (org bucket)
  "Add a bucket keyword BUCKET to the org file ORG."
  (interactive "fFile: \nsBUCKET: ")
  (with-current-buffer (find-file-noselect org)
    (let* ((tree (org-element-parse-buffer))
	   (ins (car (org-element-map tree (quote section)
		 (lambda (s)
		   (org-element-map s (quote keyword)
		     (lambda (kw) (when (equal "MACRO" (org-element-property :key kw)) (1- (org-element-property :end kw))))
		     nil nil :keyword))
		 nil t nil nil))))
      (goto-char ins)
      (insert (format "#+bucket:%s\n" bucket))
      ())))

(add-bucket "MasteringEmacs.org" "pinecone-forest")
nil

(defun hl-region (raw-hl)
  "Obtain the begin and end positions for a headline."
  (with-current-buffer (find-file-noselect (getenv "SYNC_ORG_TEMPLATE"))
    (let* ((tree (get-parsed-tree))
	   (hl (car-safe (org-element-map tree 'headline
			   (lambda (hl) (when
					    (string= raw-hl
						     (org-element-property :raw-value hl))
					  (org-element-context)))
			   nil nil t))))
      (cons
       (org-element-property :begin hl)
       (org-element-property :end hl))
      )))

(hl-region "Build Tools")

(4888 . 29646)

(defun get-hl-with-prop (org-dir hl-prop)
  "Given a directory containing an Org template file and a custom_id property name, return the headline containing that custom_id, or nil if none."
  (progn
    (cd org-dir)
    (let ((org-buf (car-safe (find-file-noselect "*.org" nil nil t))))
      (if org-buf
	  (with-current-buffer org-buf
	    (let ((tree (org-element-parse-buffer)))
	      (org-element-map tree 'headline
		(lambda (hl)
		  (let ((cid (org-element-property :CUSTOM_ID hl)))
		    (when (string= hl-prop cid)
		      (and
		       (message (format "Found the headline %s containing property %s." (org-element-property :raw-value hl) hl-prop))
		       hl))))
		nil t)))
	(and
	 (message (format "The directory %s does not contain an Org file." org-dir))
	 nil)))))

(get-hl-with-prop "~/Dev/Templates/Org" "build-tools")

(headline (:raw-value "Build Tools" :begin 4888 :end 29646 :pre-blank 0 :contents-begin 4902 :contents-end 29645 :level 1 :priority nil :tags nil :todo-keyword nil :todo-type nil :post-blank 1 :footnote-section-p nil :archivedp nil :commentedp nil :post-affiliated 4888 :FROM-FILE "Template" :CUSTOM_ID "build-tools" :APPENDIX "t" :title "Build Tools"))









;;; Add a keyword named 'bucket' just after the version macro.
;;; This function should be run from within the directory containing the Org file.
(defun add-bucket (org-file s3-bucket)
  "Add the name of the associated AWS S3 bucket to an Org templated file."
  (with-current-buffer (find-file-noselect org-file)
    (goto-char (point-min))
    (let* ((tree (org-element-parse-buffer))
	   ;; find the beginning position of the first headline to act as a limit
	   (hl1 (org-element-map tree (quote headline) (lambda (hl) (org-element-property :begin hl)) nil t)))
      ;; Check for the presence of a bucket keyword before the first headline
      (unless (re-search-forward "^#\\+bucket:" hl1 t)
	;; If no bucket keyword is found, search for a keyword MACRO with the value 'version'
	(org-element-map tree (quote keyword)
	  (lambda (kw) (when (and (string= "MACRO" (org-element-property :key kw))
				  (string-match-p "version" (org-element-property :value kw)))
			 ;; return the end position of the MACRO; subtract an empty line if there is one
			 (goto-char (- (org-element-property :end kw) (org-element-property :post-blank kw)))
			 (insert "#+bucket:" s3-bucket)
			 (newline)
			 (basic-save-buffer)
			 (message (format "Added bucket %s" s3-bucket))))
	  nil t)))))

(add-bucket "MasteringEmacs.org" "pinecone-forest.com")
nil

"Added bucket pinecone-forest.com"









(keyword (:key "MACRO" :value "version Version 0.0.108" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...))
("TITLE" "SUBTITLE" "AUTHOR" "DATE" "MACRO" "TEXINFO" "TEXINFO" "CINDEX" "CINDEX" "CINDEX" "CINDEX" "CINDEX" ...)







((keyword (:key "MACRO" :value "version Version 0.0.107" :begin 148 :end 181 :post-blank 1 :post-affiliated 148 ...)))
#+end_comment

* List of Programs
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Listing

* List of Examples
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Example

* Copying
:PROPERTIES:
:copying:  t
:END:

Copyright \copy 2020 by {{{author}}}

* Concept Index
:PROPERTIES:
:index: cp
:appendix: yes
:END:

* Program Index
:PROPERTIES:
:index: pg
:appendix: yes
:END:

* Function Index
:PROPERTIES:
:index: fn
:appendix: yes
:END:

* Variable Index
:PROPERTIES:
:index: vr
:appendix: yes
:END:


* Configuration							   :noexport:
#+startup:content

#+todo: SOMEDAY(s@) TODO(t@) INPROGRESS(i@) WAIT(w@) | CANCEL(c@) DONE(d!)

#+options: H:4

#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:<DIR CATEGORY>
#+texinfo_dir_title:<DIR TITLE>
#+texinfo_dir_desc:<DIR DESCRIPTION>
#+texinfo_printed_title:GitHubApps---Developing GitHub Apps


* Footnotes

[fn:1]In the browser, add =index.text= to the end of the URL to see the source.

[fn:2]Markdown requires the standard Perl library module Digest::MD5.


* Local Variables						   :noexport:
# Local Variables:
# fill-column: 79
# indent-tabs-mode: t
# eval: (auto-fill-mode)
# time-stamp-pattern: "8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
